{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c9b3f2-000f-4fbf-88f5-690622572aff",
   "metadata": {},
   "source": [
    "# Setting up for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb791ed-9d86-4e98-815c-46251d01242b",
   "metadata": {},
   "source": [
    "Defining imports and paths for images, labels and saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f820922-85f3-4224-8241-d87bd676e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# os.environ['MY_ENV'] = 'venv-metal'\n",
    "# print(os.getenv(\"VIRTUAL_ENV\"))\n",
    "\n",
    "# all local paths, with these modified code runs elsewhere too\n",
    "image_path = #'/directory'\n",
    "label_path = #'/birch_labels.csv'\n",
    "saved_model_path = #'/model_saving_directory/'\n",
    "\n",
    "# image dimensions\n",
    "img_dim = 224 * 1\n",
    "applied_mode = 'grayscale' # 'grayscale' / 'rgb'\n",
    "dim_3 = 1 # 1 or 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510b118-7761-4983-aa9d-e03dcdd24fd1",
   "metadata": {},
   "source": [
    "Tensorflow settings changed for quicker training if desired or needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b7b5a-ec35-4593-90e0-9b7004218d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    # Enable memory growth for GPUs to prevent memory allocation issues\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecfa41-3d21-4705-bab4-8e41961f9901",
   "metadata": {},
   "source": [
    "Define own loss functions if desired for better CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee7582-6efd-4f16-b6fc-b93aacc07dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom loss function\n",
    "def mean_4th_power_loss(y_true, y_pred):\n",
    "    # Calculate the error\n",
    "    error = y_true - y_pred\n",
    "    # Raise the error to the 4th power\n",
    "    error_4th_power = K.pow(error, 4)\n",
    "    # Return the mean of the 4th power of the error\n",
    "    return K.mean(error_4th_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b6e3e0-edfb-4ca3-8609-818ecc1c0890",
   "metadata": {},
   "source": [
    "Prepare `image_paths` either from the label file's column filenames (label.csv has columns ['filename', feature vector]) or from the image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c153a8-2f7a-48e7-acfc-91fbbd4c7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_filenames(directory):\n",
    "    image_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "            image_files.append(filename)\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3feb91d-c11b-404b-9a0d-e09e7c38878a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(label_path)\n",
    "\n",
    "image_files = get_image_filenames(image_path)\n",
    "print(image_files)\n",
    "image_paths = [image_path + '/' + i for i in df['filename']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f582fcd-8f61-4c57-aa36-9e9de20656ec",
   "metadata": {},
   "source": [
    "* Preprocessing images, inputs 3024 x 4032, 4480 x 6720\n",
    "* Split into training and validation data sets, choose `target_feature` and `target_type` for CNN training\n",
    "* add three rotated images to the training image set, increase label vector sizes accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e037776-bdfb-4c02-8948-20e7ac430150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_dim, img_dim, dim_3), color_mode = applied_mode)  # Resize to 224x224 (for example)\n",
    "    # img = load_img(image_path, target_size=(224, 224))  # Resize to 224x224 (for example)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    return img_array\n",
    "\n",
    "# Apply preprocessing to training and validation data\n",
    "all_images = []\n",
    "\n",
    "failed_images = []  # List to store failed image paths\n",
    "\n",
    "# Helper function to process each image with error handling\n",
    "def process_image_with_error_handling(img_path):\n",
    "    try:\n",
    "        return preprocess_image(img_path)  # Attempt to process image\n",
    "    except Exception as e:\n",
    "        failed_images.append(img_path)  # If an error occurs, store the image path\n",
    "        return None  # Return None or another indicator for failure\n",
    "\n",
    "# Use the helper function in the list comprehension\n",
    "approved_images = [process_image_with_error_handling(img_path) for img_path in image_paths]\n",
    "\n",
    "# Optionally, filter out failed images (if you don't want `None` values in your list)\n",
    "approved_images = [img for img in approved_images if img is not None]\n",
    "\n",
    "# Now, `failed_images` will contain the paths of the images that caused an error.\n",
    "print(f\"Failed images: {failed_images}\")\n",
    "approved_image_paths = [path for path in image_paths if path not in failed_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26efd8-e1c0-4ee2-a679-6744dbf11ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['weeping', 'antigravitropic', 'main_trunks', 'canopy_breadth', 'primary_branches', 'branch_density', 'orientation']\n",
    "target_feature = 'orientation'\n",
    "target_type = 'binary' # binary, multi-class, regression\n",
    "\n",
    "# Remove failed images from train labels\n",
    "df = df[~df['filename'].isin([i.split(\"/\")[-1] for i in failed_images])]\n",
    "labels = df[target_feature].values\n",
    "n_classes = len(df[target_feature].unique())\n",
    "# paths after taking invalid out\n",
    "applied_image_paths = approved_image_paths\n",
    "\n",
    "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(applied_image_paths, labels, test_size=0.3, random_state=42)\n",
    "train_images = [approved_images[approved_image_paths.index(i)] for i in train_image_paths]\n",
    "val_images = [approved_images[approved_image_paths.index(i)] for i in val_image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394db74-c80f-4488-9fea-ad9112ac9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add four-way rotations for pics if needed\n",
    "\n",
    "# Define a function to perform the transformations\n",
    "def augment_image(image):\n",
    "    # Perform a left rotation (90 degrees counterclockwise)\n",
    "    left_rot = np.rot90(image, k=1, axes=(0, 1))  # Rotating counterclockwise by 90 degrees\n",
    "    \n",
    "    # Perform a right rotation (90 degrees clockwise)\n",
    "    right_rot = np.rot90(image, k=3, axes=(0, 1))  # Rotating clockwise by 90 degrees\n",
    "    \n",
    "    # Perform a vertical flip (flip up and down)\n",
    "    vert_flip = np.flipud(image)  # Flipping vertically\n",
    "    \n",
    "    # Return the original image and the transformed ones\n",
    "    return np.array([image, left_rot, right_rot, vert_flip])\n",
    "\n",
    "# Apply augmentations to all images in the dataset\n",
    "augmented_images = []\n",
    "\n",
    "for img in train_images:\n",
    "    augmented_images.append(augment_image(img))\n",
    "\n",
    "# Convert the list into a numpy array\n",
    "augmented_images = np.concatenate(augmented_images, axis=0)\n",
    "\n",
    "print(augmented_images.shape)\n",
    "train_images = augmented_images\n",
    "train_labels = [item for item in train_labels for _ in range(4)]\n",
    "train_labels = np.array(train_labels).reshape(len(train_labels), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca25dbb-9699-4c96-ae76-01ecdcea4d73",
   "metadata": {},
   "source": [
    "# Creating and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9a83c-ad9f-4f42-a983-8bfe1068cabc",
   "metadata": {},
   "source": [
    "Create a Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea9c30-b49c-49f3-9652-28c40a8c2931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model_bin(input_shape=(img_dim, img_dim, dim_3)):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # For binary classification (use 'softmax' for multi-class)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss=losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_model_multi(input_shape=(img_dim, img_dim, dim_3)):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(4, (5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(4, (5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(8, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "    # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "    # Output layer for ordinal regression (single unit with linear activation)\n",
    "    model.add(layers.Dense(1, activation='linear'))  # Output a single continuous value\n",
    "    \n",
    "    # Compile the model with MSE loss for ordinal regression\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def create_model_reg(input_shape=(img_dim, img_dim, dim_3)):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(4, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4, activation='relu'))\n",
    "    \n",
    "    # Output layer for regression with linear activation\n",
    "    model.add(layers.Dense(1, activation='linear'))  # For predicting a continuous value\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "if target_type == \"binary\":\n",
    "    model = create_model_bin()\n",
    "elif target_type == \"multi-class\":\n",
    "    model = create_model_multi()\n",
    "else:\n",
    "    model = create_model_reg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea3fc9-b10a-4b73-9f89-c99a640fd08c",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afea16-9df4-4fc1-a8f0-9f5d0019d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of images to numpy arrays\n",
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(train_images, train_labels, 32)\n",
    "test_gen = DataGenerator(val_images, val_labels, 32)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_gen, \n",
    "                    epochs=10, \n",
    "                    validation_data=test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de3d50-11bd-42ad-8def-6ecc8a93a8a2",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d8117-b2eb-4056-a57a-f76ba5d11c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(val_images, val_labels)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c92107-120e-4668-9a84-77212ccdb71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run predictions on chosen set of images\n",
    "predictions = model.predict(val_images)\n",
    "\n",
    "# plot training\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.title('Train and validation by epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel(target_feature + ' error')\n",
    "# plt.savefig(saved_model_path + 'temp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3edcb-1a22-488f-9701-01cd65391ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictions, val_labels)\n",
    "plt.title('Prediction vs actual in validation')\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('actual value')\n",
    "# plt.savefig(saved_model_path + 'temp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea301209-ff4d-4a88-bd6f-0fe478b9ea31",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f6b22-ee1b-4796-96ad-44cbe0ee96b4",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad47a67-e23e-4b72-9deb-e15f27e00183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(saved_model_path + 'model_orientation.keras')  # Saves the model in the SavedModel format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f346c9-044a-48ae-b605-fe2e58ad7700",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d8cb0-9ef7-4c9e-a9fe-1f062ac36639",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(saved_model_path + 'model_antigravitropic.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
